---
layout: post
title: "스파크 클러스터"
subtitle: "스파크 클러스터의 구동 및 스케쥴링"
categories: dev
tags: big-data spark
---

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->
- [1. 스파크 클러스터](#1-스파크-클러스터)
  - [1) 스파크 런타임 아키텍쳐](#1-스파크-런타임-아키텍쳐)
  - [2) 스파크 클러스터 유형](#2-스파크-클러스터-유형)
- [2. 스파크 클러스터의 스케쥴링](#2-스파크-클러스터의-스케쥴링)
  - [1) cluster resource scheduling](#1-cluster-resource-scheduling)
  - [2) spark job scheduling](#2-spark-job-scheduling)
  - [3) data locality](#3-data-locality)
  - [4) memory scheduling](#4-memory-scheduling)
- [3. 스파크 설정](#3-스파크-설정)
  - [1) 환경 설정 파일](#1-환경-설정-파일)
  - [2) 명령줄 매개변수](#2-명령줄-매개변수)
  - [3) 시스템 환경 변수](#3-시스템-환경-변수)
  - [4) 프로그램 코드로 환경 설정](#4-프로그램-코드로-환경-설정)
  - [5) master 매개변수](#5-master-매개변수)
  - [6) 설정된 매개변수 조회](#6-설정된-매개변수-조회)
- [4. 스파크 웹 ui](#4-스파크-웹-ui)
  - [1) Jobs 페이지](#1-jobs-페이지)
  - [2) Stages 페이지](#2-stages-페이지)
  - [3) Storage 페이지](#3-storage-페이지)
  - [4) Environment 페이지](#4-environment-페이지)
  - [5) Executors 페이지](#5-executors-페이지)
- [5. 로컬 머신에서 스파크 실행](#5-로컬-머신에서-스파크-실행)
  - [1) 로컬 모드](#1-로컬-모드)
  - [2) 로컬 클러스터 모드](#2-로컬-클러스터-모드)
<!-- /code_chunk_output -->

## 1. 스파크 클러스터

### 1) 스파크 런타임 아키텍쳐

(1) 스파크 런타임 컴포넌트

- 클라이언트: 스파크 애플리케이션에 필요한 클래스 패스와 모든 설정 옵션을 준비함. 주어진 애플리케이션 인수 값을 드라이버에서 실행될 스파크 애플리케이션에 전달함.
    - spark-submit / spark-shell / spark api를 이용한 custom application 이 해당
- 드라이버: 스파크 애플리케이션의 실행을 관장하고 모니터링함.
    - 클러스터 매니저에 메모리 및 cpu 리소스를 요청
    - 애플리케이션 로직을 스테이지와 태스크로 분할
    - 여러 실행자에 태스크 전달
    - 태스크 실행 결과 수집
    - 클러스터 배포 모드 / 클라이언트 배포 모드 선택 가능
- 실행자: 요청한 태스크들을 받아서 실행하고, 결과를 드라이버로 반환하는 JVM 프로세스
    - 태스크 슬롯은 스레드로 구현됨

![Spark Cluster Architecture](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/spark_cluster_architecture.png)

### 2) 스파크 클러스터 유형

(1) 스파크 자체 클러스터

- 보안 기능 지원 x
- 잡 시작에 걸리는 시간이 yarn 클러스터에 비해 짧음.

(2) yarn 클러스터

- 큰 생태계
- 레거시 하둡과 스파크 애플리케이션의 통합이 쉬움.
- kerberos 기반 보안 HDFS는 yarn에서만 지원함.
- 클러스터를 모든 노드에 설치할 필요가 없음.
- 사용자 및 조직에 따라 애플리케이션을 격리하고 우선순위 조정 가능

(3) 메소스 클러스터

- C++ / python 애플리케이션 지원
- 다양한 유형의 리소스의 스케쥴링 가능
- 스케쥴러 프레임워크의 스케쥴러

(4) 스파크 로컬 모드

- 단일 머신에서 실행하는 스파크 자체 클러스터

## 2. 스파크 클러스터의 스케쥴링

### 1) cluster resource scheduling

- 클러스터 매니저는 각 애플리케이션이 요청한 리소스를 제공하고, 애플리케이션 실행이 끝나면 할당했던 리소스를 다시 회수함.

### 2) spark job scheduling

- 클러스터 매니저에게 리소스를 할당받을 뒤 애플리케이션 내부에서 RDD 계보를 바탕으로 잡과 스테이지, 태스크를 생성함.
- 다수의 스케쥴러 객체가 동작해 태스크를 분산함.

(1) 선입선출 스케줄러

가장 먼저 리소스를 요청한 잡이 모든 실행자의 태스크 슬롯을 필요한 만큼 차지

(2) 공정 스케줄러

스파크 잡들에 라운드 로빈 방식으로 리소스를 균등하게 분배

yarn 큐와 유사한 스케쥴러 풀을 지원하며, 가중치와 최소 지분 설정 가능

(3) 태스크 예비 실행

태스크가 실행자들에 분배되는 방식을 설정.

**낙오**(straggler) 태스크 (동일 스테이지의 다른 태스크보다 오래 걸리는 태스크) 문제를 해결할 수 있음.

### 3) data locality

(1) **데이터 지역성:** 스파크가 데이터와 최대한 가까운 위치에서 태스크를 실행하려고 노력하는 것

→ 태스크를 실행할 실행자를 선택하는 잡 스케쥴링으로 이어짐.

(2) **선호 위치**: 파티션 데이터를 저장한 호스트네임 또는 실행자 목록

- HDFS 데이터로 생성한 RDD나 캐시된 RDD를 사용할 경우에만 선호 위치 정보를 알 수 있음.
- 캐시된 RDD를 사용할 때는 스파크가 각 파티션이 캐시된 실행자 위치를 직접 관리함.

(3) **데이터 지역성 레벨**

- PROCESS_LOCAL: 파티션을 캐시한 실행자가 태스크를 실행함.
- NODE_LOCAL: 파티션에 직접 전급할 수 있는 노드에서 태스크를 실행함.
- RACK_LOCAL: 클러스터의 랙 정보를 참고할 수 있을 때 파티션이 위치한 랙에서 태스크를 실행함.
- NO_PREF: 태스크와 관련해 선호하는 위치가 없을 때.
- ANY: 데이터 지역성을 확보하지 못했을 때는 다른 위치에서 태스크를 실행함.

spark.locality.wait: 스케쥴러가 각 지역성 레벨에서 다음 지역성 레벨로 넘어가기 전까지 기다리는 시간을 지정함.

### 4) memory scheduling

클러스터 매니저가 각 프로세스에 메모리 할당 시 스파크는 잡과 태스크가 사용할 메모리 리소스를 스케쥴링하고 관리한다.

(1) 클러스터 매니저가 관리하는 메모리

spark.executor.memory 매개변수를 이용해 실행자에 할당할 메모리양을 결정할 수 있다.

(2) 스파크가 관리하는 메모리

스파크는 실행자에 할당된 메모리를 나누어서 각각 캐시 데이터와 임시 셔플링 데이터를 저장하는 데 사용한다.

spark.storage.memoryFraction 매개변수로 캐시 스토리지 크기를 설정함.

spark.shuffle.memoryFraction 매개변수로 임시 셔플링 공간 크기를 설정함.

spark.storage.safetyFraction / spark.shuffle.safetyFraction: 스파크가 메모리 사용량을 측정하고 제한하기 전에 사용량이 설정 값을 초과하는 것을 막아줌.

![Spark Memory](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/spark_memory.png)

(3) 드라이버 메모리 설정

spark.driver.memory 매개변수로 설정하며, spark-shell이나 spark-submit 스크립트로 애플리케이션을 시작할 때 적용

## 3. 스파크 설정

### 1) 환경 설정 파일

`SPARK_HOME/conf/spark-defaults.conf` 파일에 기본 값이 지정됨.

`--properties-file` 매개변수로 파일 경로를 변경할 수 있다.

### 2) 명령줄 매개변수

명령줄 매개변수를 사용해 `spark-shell`이나 `spark-submit` 명령에 인수를 지정하고 애플리케이션을 설정할 수 있다.

환경 설정 파일로 설정한 값보다 명령줄 매개변수로 지정한 값이 우선시된다.

### 3) 시스템 환경 변수

`spark-env.sh`나 os 환경 변수를 사용해 설정할 수 있다. 가장 낮은 우선순위로 적용된다.

### 4) 프로그램 코드로 환경 설정

`SparkConf`클래스로 프로그램 내에서 직접 스파크 환경 매개변수를 설정할 수도 있다. (`SparkContext`객체를 생성하기 전에 `SparkConf`객체의 설정을 마쳐야 한다.)

가장 높은 우선 순위를 가진다.

### 5) master 매개변수

애플리케이션을 실행할 스파크 클러스터 유형을 지정한다.

`spark-submit --master <master_connection_url>`로 전달할 수 있다.

프로그램 코드 내부에서 설정할 수도 있지만, 애플리케이션 이식성을 해치기에 추천되지 않는다.

### 6) 설정된 매개변수 조회

`sc.getConf.getAll`메서드를 호출해 spark context에 정의 및 로드된 모든 환경 매개변수의 목록을 가져올 수 있다.

## 4. 스파크 웹 ui

다양한 스파크의 환경과 잡 실행 통계 정보를 제공한다.

### 1) Jobs 페이지

현재 실행 중인 잡, 완료된 잡, 실패한 잡의 통계 정보를 제공한다.

### 2) Stages 페이지

스테이지의 시작 시각, 실행 시간, 실행 현황, 입출력 데이터의 크기, 셔플링 읽기/ 쓰기 데이터양을 확인할 수 있다.

### 3) Storage 페이지

캐시된 RDD 정보와 캐시 데이터가 점유한 메모리, 디스크, 타키온 스토리지 용량을 보여준다.

### 4) Environment 페이지

스파크 환경 매개변수뿐만 아니라 자바 및 스칼라의 버전, 자바 시스템 속성, 클래스패스 정보를 확인할 수 있다.

### 5) Executors 페이지

클러스터 내 모든 실행자 목록과 각 실행자별 메모리 사용량을 포함한 여러 통계 정보를 제공함.

## 5. 로컬 머신에서 스파크 실행

### 1) 로컬 모드

클라이언트 JVM 내에 드라이버와 실행자를 각각 하나씩만 생성함.

스레드를 여러 개 생성해 태스크를 병렬로 실행할 수 있음.

클라이언트 프로세스를 클러스터의 단일 실행자처럼 사용

master 매개변수에 지정된 스레드 개수는 병렬 태스크 개수를 의미함.

### 2) 로컬 클러스터 모드

master 매개변수에 `local-cluster[<n>,<c>,<m>]`입력으로 사용 가능하다.