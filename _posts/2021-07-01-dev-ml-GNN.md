---
layout: post
title: "Training Graph Neural Networks"
subtitle: "GNN study"
categories: dev
tags: ml/dl GNN
---

- 목차
  - Prediction Head
  - Supervised vs Unsupervised
  - Loss function
  - Metrics

---

## Prediction Head

### Node-level prediction

> Notion: node 예측이기에 node embedding을 예측에 바로 사용 가능

### Edge-level prediction

> Notion: node u와 node v를 잇는 edge에 대해 예측을 하고자 할 때는 두 node의 embedding을 종합해서 사용해야 하는데, 이때 여러가지 option이 있다.

- Concatenation + Linear
- Dot Product

### Graph-level prediction

> Notion: Graph에 대해 예측을 하고자 할 때는 여러 node의 embedding을 종합해서 사용해야 하는데, 이때 여러가지 option이 있다.

- Global mean pooling
- Global max pooling
- Global sum pooling
  -> 간단하게 사용하기는 좋지만, 정보 손실이 일어난다는 단점이 있음.

  **<br/>Hierarchical globall pooling**

  ![Hierarchical Global Pooling [Ref: stanford 224W]](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/hierachical_pooling.png)

  > Notion: Aggregate all the node embedding hierarchically

  ex: DiffPool idea

  - Node embedding을 Hierarchically pool하여 clustering에 사용
  - Levarage 2 independent GNNs at each level
    - GNN A: node embedding을 계산하는 네트워크
    - GNN B: node가 어떤 cluster에 속할 지 학습하는 네트워크
  - GNN A와 B는 병렬적으로 학습이 가능하다는 장점이 있음

## Supervised vs Unsupervised

### Supervised

- task를 node/edge/graph label에 대한 task로 reduce해라.

### Unsupervised

- 문제: external label이 없다.
- 해결책: supervision signal을 graph안에서 찾아라!
  - node-level: node statistics
  - edge-level: link prediction
  - graph-level: graph statistics

## Loss Function

- Classification Loss: Cross Entropy Loss 등
- Regression Loss: MSE Loss 등

## Metrics

- regression: RMSE, MAE 등
- classification: accuracy, precision/recall등
