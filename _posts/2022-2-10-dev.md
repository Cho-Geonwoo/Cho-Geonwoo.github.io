---
layout: post
title: "Spark 자체 클러스터 (Spark standalone cluster)"
subtitle: "클러스터 구성 및 작동"
categories: dev
tags: big-data spark
---

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 스파크 자체 클러스터의 컴포넌트들](#1-스파크-자체-클러스터의-컴포넌트들)
  - [1) **클러스터 배포 모드 아키텍쳐**](#1-클러스터-배포-모드-아키텍쳐)
  - [2) 클러스터 배포 모드 구동 순서](#2-클러스터-배포-모드-구동-순서)
  - [3) 워커 프로세스 수 조정](#3-워커-프로세스-수-조정)
- [2. 스파크 자체 클러스터 시작](#2-스파크-자체-클러스터-시작)
  - [1) shell script로 시작](#1-shell-script로-시작)
  - [2) 수동으로 클러스터 시작](#2-수동으로-클러스터-시작)
  - [3) 스파크 프로세스 조회](#3-스파크-프로세스-조회)
  - [4) 마스터 고가용성 및 복구](#4-마스터-고가용성-및-복구)
- [3. 웹 UI](#3-웹-ui)
- [4. 애플리케이션 실행](#4-애플리케이션-실행)
  - [1) 드라이버의 위치](#1-드라이버의-위치)
  - [2) 실행자 개수 지정](#2-실행자-개수-지정)
  - [3) 추가 클래스패스 항목 및 파일 지정](#3-추가-클래스패스-항목-및-파일-지정)
  - [4) 애플리케이션 강제 종료](#4-애플리케이션-강제-종료)
  - [5) 애플리케이션 자동 재시작](#5-애플리케이션-자동-재시작)
- [5. 히스토리 서버와 이벤트 로깅](#5-히스토리-서버와-이벤트-로깅)

<!-- /code_chunk_output -->

---

## 1. 스파크 자체 클러스터의 컴포넌트들

### 1) **클러스터 배포 모드 아키텍쳐**

![Architecture](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/spark_standalone_cluster/architecture.png)

### 2) 클러스터 배포 모드 구동 순서

1단계: client 프로세스가 master에 application을 제출한다.

2단계: master가 1번 노드의 워커에 드라이버를 시작하라고 전달한다.

3단계: 드라이버 jvm을 실행한다.

4단계: 마스터가 1 / 2번 노드에 실행자를 시작하라고 지시한다.

5단계: 두 워커가 각각 실행자 jvm을 시작한다.

6단계: 드라이버가 실행자와 통신하며 스파크 애플리케이션을 시작한다.

### 3) 워커 프로세스 수 조정

워커당 실행자를 여러 개 생성할 수도 있지만, JVM 힙이 너무 크고 가비지 컬렉션이 잡 성능에 영향을 미치면 워커 프로세스 개수를 늘릴 수 있다.

## 2. 스파크 자체 클러스터 시작

### 1) shell script로 시작

`SPARK_HOME/sbin` directory에 있는 시작 스크립트로 스파크를 시작할 수 있다.

`[start-master.sh](http://start-master.sh)` : 마스터 프로세스를 시작한다.

`[start-slaves.sh](http://start-slaves.sh)` : ssh protocol을 사용해 SPARK_HOME/conf/slaves 파일에 나열된 모든 머신에 접속하고 워커 프로세스를 시작한다.

`[start-all.sh](http://start-all.sh)` : 내부적으로 `[start-master.sh](http://start-master.sh)` 호출 뒤 `[start-slaves.sh](http://start-slaves.sh)` 를 호출한다.

### 2) 수동으로 클러스터 시작

**윈도우에서는 오직 이 방법으로만 스파크 자체 클러스터를 사용할 수 있다.**

`SPARK_HOME/bin/spark-class` 스크립트에 스파크 마스터 클래스 / 워커 클래스의 이름을 인수로 지정해서 호출해야 한다. 워커 시작 시에는 master url도 지정해야 한다.

```bash
spark-class org.apache.spark.deploy.master.Master
spark-class org.apahce.spark.deploy.worker.Worker spark://<IPADDR>:<PORT>
```

### 3) 스파크 프로세스 조회

```bash
jps
```

JVM 프로세스 상태 도구를 이용해 프로세스를 조회할 수 있다.

### 4) 마스터 고가용성 및 복구

**(1) 파일 시스템 기반**

마스터는 등록된 모든 워커와 실행 중인 애플리케이션 정보를 `spark.deploy.recoveryDirectory` 에 지정된 디렉토리에 보관한다.

**(2) 주키퍼 기반**

주키퍼: 네이밍 저장소, 분산 동기화 및 그룹 서비스 기능을 지원하는 빠르고 간편한 시스템이다.

주키퍼에 등록된 모든 워커와 실행 중인 애플리케이션 정보를 보관한다.

`spark.deploy.recoveryDirectory` 를 `ZOOKEEPER`로 지정해 활성화한다. 또, `spark.deploy.zookeper.url` 매개변수에 지정된 url로 접근 가능해야 한다.

## 3. 웹 UI

스파크 자체 클러스터의 웹 UI는 마스터와 워커 정보를 보여 준다.

## 4. 애플리케이션 실행

### 1) 드라이버의 위치

`spark-submit` 스크립트에 `--deploy-mode client` 인수를 지정하면 드라이버를 클라이언트에서 실행할 수 있고, 지정하지 않으면 기본으로 클라이언트 배포 모드가 사용된다.

`--deploy-mode cluster` 인수를 지정하면 드라이버를 클러스터 내부에서 실행할 수 있다.

클러스터 배포 모드로 드라이버를 실행 시 어떤 워커가 드라이버를 실행시킬 지 알 수 없기에 모든 워커 머신의 로컬 디스트로 JAR 파일을 복사하거나 애플리케이션 JAR 파일을 HDFS에 복사하고 JAR파일 이름에 HDFS URL을 지정해야 한다.

### 2) 실행자 개수 지정

`spark.deploy.defaultCores`: 애플리케이션이 할당받는 기본 core 개수를 설정

`spark.cores.max`: 애플리케이션의 전체 코어 개수를 설정

`spark.executors.cores` : 애플리케이션의 실행자당 코어 개수를 설정

변수들의 default 값은 무한이다.

### 3) 추가 클래스패스 항목 및 파일 지정

(1) SPARK_CLASSPATH 환경 변수를 사용해 추가 JAR 파일을 드라이버 및 실행자에 전달할 수 있다.

(2) `spark-submit`의 `--driver-class-path` 와 `--driver-library-path` 명령줄 매개변수를 사용해 드라이버에 적용할 라이브러리 경로를 전달할 수 있다.

(3) `spark-submit` 스크립트의 `—jars` 매개변수에 JAR 파일을 지정하거나 `--files` 옵션으로 일반 파일을 워커에 전달할 수 있다.

—jars 옵션에는 다양한 위치의 JAR 파일을 지정할 수 있다.

- file: 지정된 파일을 각 워커에 복사
- local: 워커 머신 내 동일한 위치의 로컬 파일을 지정
- hdfs: HDFS 파일 경로를 지정한다.
- http:, https:, ftp: 파일의 URL을 지정한다.

(4) `SparkContext`의 `addJar` 또는 `addFile` 을 호출해 프로그램 내부에서 JAR 및 파일을 추가할 수도 있다.

(5) `spark-submit` 로 파이썬 애플리케이션 제출 시에는 `--py-files` 옵션으로 `.egg` 나 `.zip.py` 파일을 추가할 수 있다.

### 4) 애플리케이션 강제 종료

`spark-class org.cache.apache.spark.deploy.Client kill <master_URL> <driver_ID>`

명령어로 클러스터에서 실행 중인 애플리케이션을 강제 종료할 수 있다.

### 5) 애플리케이션 자동 재시작

클러스터 배포 모드로 애플리케이션을 제출할 때 `--supervise` 옵션을 지정하면, 드라이버 프로세스에 장애가 발생하거나 비정상 종료시 드라이버를 재시작한다.

## 5. 히스토리 서버와 이벤트 로깅

- 이벤트 로깅 활성화 시 애플리케이션의 실행 정보 및 데이터를 마스터 웹 UI에서 확인할 수 있다.
- 마스터 프로세스 재시작/ 중단 시에도 웹 UI로 정보를 보기 위해 히스토리 서버를 활용할 수 있다.