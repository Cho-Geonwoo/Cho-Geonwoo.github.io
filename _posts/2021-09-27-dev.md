---
layout: post
title: "Open Source Review"
subtitle: "Pytorch Scatter"
categories: dev
tags: ML/DL Open-source-review pytorch_scatter pytorch
---

- 목차
  1. 계기
  2. Pytorch Scatter Library
  3. 사용 방법
  4. Code Review
  5. 소감

---

## 1. 계기

최근 GNN에 한창 빠져 있어 **Pytorch Geometric** library를 보던 와중, pytorch geometric library의 engine에 [Pytorch Scatter](https://github.com/rusty1s/pytorch_scatter)라는 library가 사용된 것을 보았고, 해당 라이브러리가 사용된 이유가 궁금해져 어떤 라이브러리인지, 그리고 구현은 어떻게 되어있는지 살펴보고자 이번 open source review를 하게 되었다. 관심이 간 또다른 이유 중 하나는, 상당수의 코드가 cpp로 짜여져 있다는 점이었다. 평소에 pytorch의 C++ 구현체는 어떻게 사용되는지 관심이 많았는데, 이번 기회에 오랜만에 C++ 복습도 하고, 조금 더 시스템에 가까운 머신러닝 코드도 공부를 해보고자 코드 분석을 시작하게 되었다.

## 2. Pytorch Scatter Library

**Pytorch Scatter** library는 src array와 index array가 있을 때, sum/mean/min/max등의 연산을 통해 특정한 output을 내놓도록 설계된 library이다. 다음 사진은 sum 연산에 대한 예시이다.

![Scatter](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/scatter.svg)

각 연산들에 대한 자세한 설명은 [Documentation](https://pytorch-scatter.readthedocs.io/en/latest/)을 참고해주길 바란다.

## 3. 사용 방법

pytorch >= 1.8.0이 설치 되어 있는 conda 환경에서 다음과 같은 command로 pytorch-scatter library를 설치한다.

`conda install pytorch-scatter -c pyg`

사용 예시는 다음과 같다.

```python
import torch
from torch_scatter import scatter_max

src = torch.tensor([[2, 0, 1, 4, 3], [0, 2, 1, 3, 4]])
index = torch.tensor([[4, 5, 4, 2, 3], [0, 0, 2, 2, 1]])

out, argmax = scatter_max(src, index, dim=-1)

print(out)
#tensor([[0, 0, 4, 3, 2, 0], [2, 4, 3, 0, 0, 0]])

print(argmax)
#tensor([[5, 5, 3, 4, 0, 1], [1, 4, 3, 5, 5, 5]])
```

## 4. Code Review

개략적인 폴더 structure는 다음과 같이 이루어져 있다.

- csrc: Pytorch Scatter library의 c++ 구현체가 담긴 폴더
- test: pytest를 이용한 code testing
- torch_scatter: c++ 구현체를 python으로 이용할 수 있게 formatting하는 code
- setup.py: cpp코드를 pytorch의 Extension class를 이용해 pip을 이용할 수 있게끔 setting하는 코드
- CMakeLists.txt: cpp코드의 binary 파일 생성을 위한 cmake 설정을 담은 파일
- ETC: CI/CD, conda build sh script 파일 등등.. 위 파일들에 비해 중요하지 않다고 생각해 별도로 묶었음!

먼저 test code를 보고 코드가 어떻게 사용되는 지 확인해보자.

```python
tests = [
    {
        'src': [1, 3, 2, 4, 5, 6],
        'index': [0, 1, 0, 1, 1, 3],
        'dim': 0,
        'sum': [3, 12, 0, 6],
    },
]

@pytest.mark.parametrize('test,reduce,dtype,device',
                         product(tests, reductions, dtypes, devices))
def test_out(test, reduce, dtype, device):
    src = tensor(test['src'], dtype, device)
    index = tensor(test['index'], torch.long, device)
    dim = test['dim']
    expected = tensor(test[reduce], dtype, device)

    out = torch.full_like(expected, -2)

    getattr(torch_scatter, 'scatter_' + reduce)(src, index, dim, out)

    if reduce == 'sum' or reduce == 'add':
        expected = expected - 2
    assert torch.all(out == expected)
```

index 0에 해당하는 숫자는 1과 2, index 1에 해당하는 숫자는 3, 4, 5, index 3에 해당하는 숫자는 6이고, 각각 index별로 summation을 한다면 3, 12, 0, 6이 된다.

다음으로 torch_scatter 폴더의 `scatter.py`에 있는 코드를 살펴보자. 가져다 쓸 수 있는 여러 함수들이 있는데, 대표적으로 `scatter_max` 함수만 살펴보자.

```python
def scatter_max(
        src: torch.Tensor, index: torch.Tensor, dim: int = -1,
        out: Optional[torch.Tensor] = None,
        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:
    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)

def scatter(src: torch.Tensor, index: torch.Tensor, dim: int = -1,
            out: Optional[torch.Tensor] = None, dim_size: Optional[int] = None,
            reduce: str = "sum") -> torch.Tensor:
    if reduce == 'sum' or reduce == 'add':
        return scatter_sum(src, index, dim, out, dim_size)
    if reduce == 'mul':
        return scatter_mul(src, index, dim, out, dim_size)
    elif reduce == 'mean':
        return scatter_mean(src, index, dim, out, dim_size)
    elif reduce == 'min':
        return scatter_min(src, index, dim, out, dim_size)[0]
    elif reduce == 'max':
        return scatter_max(src, index, dim, out, dim_size)[0]
    else:
        raise ValueError
```

위 코드에서 볼 수 있듯이, `scatter_max` 함수는 `torch.ops.torch_scatter.scatter_max` 구현체를 사용하고, `scatter` 함수는 **factory pattern**의 형태로 여러 method들을 지원하고 있다. 근데... pytorch에는 저런 함수가 없는데..? 하시면 정확하게 보셨다. 위 함수는 c++로 구현되어 pytorch에서 import해 사용할 수 있도록 작성되었다. `setup.py`를 보면 확인할 수 있다.

```python
def get_extensions():
    ...
    for main, suffix in product(main_files, suffices):
        ...
        extension = Extension(
            f'torch_scatter._{name}_{suffix}',
            sources,
            include_dirs=[extensions_dir],
            define_macros=define_macros,
            extra_compile_args=extra_compile_args,
            extra_link_args=extra_link_args,
        )
        extensions += [extension]

    return extensions

setup(
    name='torch_scatter',
    version='2.0.8',
    author='Matthias Fey',
    author_email='matthias.fey@tu-dortmund.de',
    url='https://github.com/rusty1s/pytorch_scatter',
    description='PyTorch Extension Library of Optimized Scatter Operations',
    keywords=['pytorch', 'scatter', 'segment', 'gather'],
    license='MIT',
    python_requires='>=3.6',
    install_requires=install_requires,
    setup_requires=setup_requires,
    tests_require=tests_require,
    extras_require={'test': tests_require},
    ext_modules=get_extensions() if not BUILD_DOCS else [],
    cmdclass={
        'build_ext':
        BuildExtension.with_options(no_python_abi_suffix=True, use_ninja=False)
    },
    packages=find_packages(),
)
```

코드가 상당히 길어 부분 생략한 점 양해바란다. 코드에 있다시피, pytorch의 `cpp_extension`을 이용해 cpp코드를 build하고 있다. (~~아직까진 볼만하다~~) 마지막으로 cpp 실제 구현체를 살펴보자! cpp 구현체도 `scatter_max`에 대해서만 살펴보도록 하겠다.

`scatter.cpp`의 `ScatterMax` class에 실 구현체가 있는데, 코드는 다음과 같다.

```cpp
class ScatterMax : public torch::autograd::Function<ScatterMax> {
public:
  static variable_list forward(AutogradContext *ctx, Variable src,
                               Variable index, int64_t dim,
                               torch::optional<Variable> optional_out,
                               torch::optional<int64_t> dim_size) {
    dim = dim < 0 ? src.dim() + dim : dim;
    ctx->saved_data["dim"] = dim;
    ctx->saved_data["src_shape"] = src.sizes();

    index = broadcast(index, src, dim);
    auto result = scatter_fw(src, index, dim, optional_out, dim_size, "max");
    auto out = std::get<0>(result);
    auto arg_out = std::get<1>(result).value();
    ctx->save_for_backward({index, arg_out});
    ctx->mark_non_differentiable({arg_out});
    if (optional_out.has_value())
      ctx->mark_dirty({optional_out.value()});
    return {out, arg_out};
  }

  static variable_list backward(AutogradContext *ctx, variable_list grad_outs) {
    auto grad_out = grad_outs[0];
    auto saved = ctx->get_saved_variables();
    auto index = saved[0];
    auto arg_out = saved[1];
    auto dim = ctx->saved_data["dim"].toInt();
    auto src_shape = list2vec(ctx->saved_data["src_shape"].toIntList());
    src_shape[dim] += 1;
    auto grad_in = torch::zeros(src_shape, grad_out.options());
    grad_in.scatter_(dim, arg_out, grad_out);
    grad_in = grad_in.narrow(dim, 0, src_shape[dim] - 1);
    return {grad_in, Variable(), Variable(), Variable(), Variable()};
  }
};
```

코드가 상당히 길어 (~~cpp이라~~) 읽기 싫은 비주얼이지만, 사실 python에서 pytorch를 하는 것과 똑같게 forward method와 backward method를 구현한 것에 불과하다. 이 `ScatterMax` class는 다음과 같이 등록되어 python에서 사용할 수 있게 된다.

```cpp
std::tuple<torch::Tensor, torch::Tensor>
scatter_max(torch::Tensor src, torch::Tensor index, int64_t dim,
            torch::optional<torch::Tensor> optional_out,
            torch::optional<int64_t> dim_size) {
  auto result = ScatterMax::apply(src, index, dim, optional_out, dim_size);
  return std::make_tuple(result[0], result[1]);
}

static auto registry = torch::RegisterOperators()
                           .op("torch_scatter::scatter_sum", &scatter_sum)
                           .op("torch_scatter::scatter_mul", &scatter_mul)
                           .op("torch_scatter::scatter_mean", &scatter_mean)
                           .op("torch_scatter::scatter_min", &scatter_min)
                           .op("torch_scatter::scatter_max", &scatter_max);
```

`ScatterMax`에서 눈여겨봐야 할 부분이 한 가지 있는데, `scatter_fw`라는 이름의 함수다. 해당 함수에서 cuda의 사용 유무에 따라 cpu를 위한 알고리즘 구현체를 사용할 것인지, gpu를 위한 알고리즘 구현체를 사용할 것인지 선택한다. gpu에 대한 구현체는 .cu 파일로 작성이 되어 있는데, cuda driver 쪽 코드는 별도의 이해를 요구하니 생략하도록 하겠다. cpu 구현체에 대한 요약은 다음과 같다.

```cpp
std::tuple<torch::Tensor, torch::optional<torch::Tensor>>
scatter_cpu(torch::Tensor src, torch::Tensor index, int64_t dim,
            torch::optional<torch::Tensor> optional_out,
            torch::optional<int64_t> dim_size, std::string reduce) {

    // input 검증 부분

    // input 변형 및 메모리 할당 부분

    // algorithm 결정 부분

    // 예외 처리 부분

    // 실제 알고리즘 부분
  auto index_info = getTensorInfo<int64_t>(index);
  AT_DISPATCH_ALL_TYPES_AND(at::ScalarType::Half, src.scalar_type(), "_", [&] {
    auto src_data = src.data_ptr<scalar_t>();
    auto out_data = out.data_ptr<scalar_t>();

    int64_t i, idx;
    AT_DISPATCH_REDUCTION_TYPES(reduce, [&] {
      if (!optional_out.has_value())
        out.fill_(Reducer<scalar_t, REDUCE>::init());

      for (auto b = 0; b < B; b++) {
        for (auto e = 0; e < E; e++) {
          for (auto k = 0; k < K; k++) {
            i = b * E * K + e * K + k;
            idx = index_info.data[IndexToOffset<int64_t>::get(i, index_info)];
            Reducer<scalar_t, REDUCE>::update(
                out_data + b * N * K + idx * K + k, src_data[i],
                arg_out_data + b * N * K + idx * K + k, e);
          }
        }
      }

      if (!optional_out.has_value() && (REDUCE == MIN || REDUCE == MAX))
        out.masked_fill_(out == Reducer<scalar_t, REDUCE>::init(), (scalar_t)0);
    });
  });

  return std::make_tuple(out, arg_out);
}

```

실제 알고리즘 부분은 `Reducer` class를 이용해 구현되어 있는데 맛뵈기 삼아 살짝 코드를 남겨두었다. 어쩌면 굉장히 복잡하다고 느낄 수도, 많지 않은 코드라고 느낄 수도 있는데, 신기한 구조로 코드가 구성되어 있어 코드를 재밌게 리뷰할 수 있었던 것 같다.

## 5. 소감

C++을 하도 오랜만에 보기도 했고, pytorch c++ library의 사용법을 몰라 엄청 헤매기도 하고, CMakeLists 파일을 처음 봐서 굉장히 당황하기도 하고, Cuda driver에 대한 이해도가 낮아 완벽하게 코드를 이해하지 못하기도 했고, 심지어 code 사용법을 보려고 test 코드를 살펴봤는데, test 코드도 내가 잘 모르는 pytest framework를 이용해 작성되어 있어서 총체적으로 어려웠다.

그래서... 사실 모든 코드를 완벽하게 이해하지는 못한 것 같다. 그래도, pytorch의 cpp 구현체와 python과 연결시키는 법에 대해서 어느 정도 감을 잡게 됐고, cuda driver의 효율적인 이용을 위해서는 많은 연산이 요구되는 부분만이 cuda를 사용하도록 꼼꼼한 코드를 작성해야 된다는 점을 배웠다. 또, CmakeLists 파일을 작성하는 법을 익혔고, cuda와 cpu를 동시에 사용하기 위한 cpp 코드는 어떤 식으로 작성해야 되는지 눈요기를 할 수 있었다.

마음 같아선 cpp코드를 각 잡고 뜯어보고 싶지만, 내 실력이 부족해 당장 모든 코드를 이해하려면 굉장히 오랜 시간이 걸릴 것 같다. 다른 cpp 코드들을 살펴보고, cuda에 대한 이해도를 높여 실력을 기르고 난다음 다시... 도전해보겠다! 아자아자 화이팅!!!
