---
layout: post
title: "MESOS에서 스파크 실행"
subtitle: "MESOS 아키텍쳐의 구성 및 실행 방법"
categories: dev
tags: big-data spark
---

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->
<!-- /code_chunk_output -->

---


## 1) 메소스 아키텍쳐

(1) Coarse-grained

![Architecture](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/spark_mesos_cluster/architecture.png)

1.  Is 메소스 슬레이브는 자신의 리소스를 마스터에 제안한다.
2. 스파크 드라이버가 실행하는 메소스 전용 스케쥴러는 자신을 메소스 마스터에 등록한다.
3. 메소스 마스터는 스파크 메소스 스케줄러에 가용 리소스를 제안한다.
4. 스파크의 메소스 스케줄러는 마스터가 제안한 리소스 일부를 수용하고, 사용할 리소스 목록과 이 리소스로 실행할 태스크 목록을 메소스 마스터에 전송한다.
5. 스케줄러가 요청한 리소스를 사용해 태스크를 시작하라고 슬레이브에 지시한다.
6. 슬레이브는 실행자를 시작하며, 메소스 실행자는 태스크 컨테이너에서 스파크 실행자를 시작한다.
7. 스파크 실행자는 스파크 드라이버에 접속해 직접 통신하고 스파크 태스크를 실행한다.

(2) 메소스 컨테이너

한 슬레이브가 실행하는 여러 프로세스들의 리소스를 격리해 태스크들이 서로 간섭하지 않도록 한다.

- cgroups: 프로세스의 리소스 사용을 제한하고 격리하는 리눅스 커널의 기능이다. 컨트롤 그룹은 한정된 리소스를 할당받은 프로세스 집합이다.
- 도커 컨테이너

(3) 마스터 고가용성

클러스터가 마스터 프로세스를 여러 개 사용하도록 설정할 수 있다.

## 2) 리소스 스케쥴링

(1) 스케쥴링 구성

**리소스 할당 모듈** (resouce-allocation module)이 어떤 리소스를 어떤 프레임워크에 어떤 순서로 제안할지 결정한 후, **프레임워크 스케쥴러**가 수용된 리소스를 바탕으로 어떤 태스크를 먼저 시작할 것인지 결정한다.

(2) 리소스 할당 정책

기본으로 DRF (Dominant Resource Fairness, DRF) 알고리즘을 사용한다. 

**DRF**

1.  각 프레임워크의 리소스를 모니터링하고 각 프레임워크가 많이 사용하는 **우세 리소스** 유형을 판단
2. 각 프레임워크의 **우세 지분**을 계산한다.
3. 우세 지분이 가장 낮은 프레임워크에 새로운 리소스를 먼저 제안한다.

(3) 역할과 가중치에 따른 리소스 차등 할당

**역할**: 사용자 그룹 / 프레임워크 그룹을 의미

**가중치**: 리소스를 제안하는 우선 순위를 지정

- 마스터를 시작하는 명령에 `--roles` 옵션을 전달하거나 각 역할별 가중치를 전달해 지정한다. (`/etc/mesos-master/roles` 와 `/etc/mesos-master/weights` 파일에 각각 저장할 수도 있다.)
- 특정 역할에 할당할 슬레이브 리소스를 따로 남겨둘 수 있다. `--resources` 매개변수 값을 `'resource_name(role_name1): value1;resource_name2(role_name2):value2'` 형식으로 지정해 사용한다.

(4) 메소스 속성 및 스파크의 제한 속성

- `--attributes` 매개변수로 각 슬레이브에 사용자 정의 속성을 지정할 수 있다.

사용자 정의 속성 종류: 운영체제 유형 및 버전, 슬레이브가 실행 중인 랙 정보

- `spark.mesos.constraints` 매개변수로 속성 제한 조건을 지정할 수 있다.

## 3) 메소스에 스파크 애플리케이션 제출

`spark-submit --master mesos://<master_hostname>:<master_port>` 

**클러스터 배포 모드로 스파크 실행**

`start-mesos-dispatcher.sh --master mesos://zk://<bind_address>:2181/mesos`

bind_addresss는 주키퍼를 사용한 마스터 URL이다. 위 스크립트로 MesosClusterDispatcher 프로세스를 시작하고, 7077번 포트로 들어오는 클라이언트의 요청을 수신한다. `--deploy-mode` 를 `cluster` 로 지정해 메소스 마스터 대신 이 프로세스에 애플리케이션을 제출할 수 있다.

## 4) 도커로 스파크 실행

(1) 도커 이미지 생성

```docker
FROM mesosphere/mesos:0.20.1
RUN apt-get update && \
		apt-get install -y python libnss3 openjdk-7-headless curl
RUN mkdir /opt/spark && \
		curl http://www-us.apache.org/dist/spark/spark-2.0.2/spark-2.0.2-bin-hadoop2.7.tgz | tar -xzC /opt
ENV SPARK_HOME /opt/spark-2.0.2-bin-hadoop2.7
ENV MESOS_NATIVE_JAVA_LIBRARY /usr/local/lib/libmesos.so
```

`docker build -t spark-mesos ./` 

위 빌드 작업을 메소스 클러스터의 모든 슬레이브 머신에서 동일하게 실행해야 한다.

(2) 메소스가 도커를 사용하도록 설정

메소스 클러스터의 각 슬레이브 머신에서 다음 명령어를 순차적으로 실행하자.

`echo 'docker, mesos' > /etc/mesos-slave/containerizers`

`echo '5mins' > /etc/mesos-slave/executor_registration_timeout`

`sudo service mesos-slave restart`

(3) 도커 이미지에서 스파크 태스크 실행

`spark-defaults.conf` 파일에 다음 내용을 입력한다.

```bash
spark.mesos.executor.docker.image spark-mesos
spark.mesos.executor.home /opt/spark-2.0.2-bin-hadoop2.7
spark.executorEnv.MESOS_NATIVE_JAVA_LIBRARY /usr/local/lib/libmesos.so
```

`spark-submit --master mesos://zk://<your_hostname>:2181/mesos --class org.apache.spark.examples.SparkPi examples/jars/spark-examples_2.11-2.0.2.jar`