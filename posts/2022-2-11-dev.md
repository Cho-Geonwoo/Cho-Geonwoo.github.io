---
layout: post
title: "YARN에서 스파크 실행"
subtitle: "YARN 아키텍쳐의 구성 및 자체 클러스터와의 차이"
categories: dev
tags: big-data spark
---

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->
- [1) Yarn 아키텍쳐](#1-yarn-아키텍쳐)
- [2) YARN 모드](#2-yarn-모드)
- [3) 리소스 스케줄링](#3-리소스-스케줄링)
- [4) YARN 드라이버 프로세스 시작](#4-yarn-드라이버-프로세스-시작)
- [5) YARN에서 스파크 설정](#5-yarn에서-스파크-설정)
- [6) 스파크 잡에 할당할 리소스 설정](#6-스파크-잡에-할당할-리소스-설정)
- [7) 로그 조회](#7-로그-조회)
- [8) 보안](#8-보안)
- [9) 동적 리소스 할당](#9-동적-리소스-할당)
<!-- /code_chunk_output -->

---


## 1) Yarn 아키텍쳐

![Architecture](https://raw.githubusercontent.com/Cho-Geonwoo/Cho-Geonwoo.github.io/master/assets/img/contents/spark_yarn_cluster/architecture.png)


(1) 클라이언트는 애플리케이션을 리소스 매니저에 제출한다.

(2) 리소스 매니저는 먼저 노드 매니저 중 하나를 선정해 스파크 애플리케이션 마스터를 실행할 컨테이너를 시작하라고 요청함.

(3) 노드 매니저가 AM 컨테이너를 시작한다.

(4) 애플리케이션에 필요한 리소스를 리소스 매니저에 요청한다.

(5) 노드 매니저에 실행자 컨테이너를 시작하라고 요청한다.

(6) 노드 매니저들이 실행자를 시작한다.

(7) 스파크 드라이버가 스파크 실행자들과 직접 통신한다.

## 2) YARN 모드

- 자체 (로컬) 모드: YARN을 단일 자바 프로세스로 실행한다.
- 의사 분산 모드 (pseudo-distributed mode): 단일 머신에서 모든 하둡 데몬을 실행한다.
- 완전 분산 모드: YARN을 여러 머신에서 실행한다.

## 3) 리소스 스케줄링

스파크 애플리케이션에 리소스를 할당하는 작업

(1) FIFO 스케쥴러

먼저 요청한 애플리케이션이 우선적으로 리소스를 할당받는다.

(2) 용량 스케쥴러

YARN 클러스터를 여러 조직이 공유하면서 각 조직에 일정 용량의 리소스를 항상 보장한다.

큐 단위로 리소스를 스케쥴링한다.

(3) 공정 스케쥴러

모든 애플리케이션에 최대한 공평한 지분의 리소스를 할당한다.

## 4) YARN 드라이버 프로세스 시작

**클러스터 내부에서 시작**

`--master yarn --deploy-mode cluster`

`--master yarn-cluster`

**클라이언트에서 실행**

`--master yarn --deploy-mode client`

`--master yarn-client`

**종료**

`yarn application -kill <application_id>`

## 5) YARN에서 스파크 설정

스파크를 클라이언트 노드에만 설치해도 어셈블리 JAR 파일과 설정 옵션을 자동으로 YARN 컨테이너에 전송된다.

단 YARN을 지원하는 스파크 배포 패키지를 사용해야 한다.

## 6) 스파크 잡에 할당할 리소스 설정

(1) 애플리케이션에 할당할 CPU 리소스 설정

실행자 수를 할당해주기 위해 애플리케이션을 YARN에 제출할 때 다음 명령줄 옵션을 사용해야 한다.

`--num-executors` : 실행자 개수를 변경한다.

`--executor-cores` : 각 실행자에 할당할 코어 개수를 변경한다.

(2) YARN에서 실행하는 스파크의 메모리 관리

`spark.yarn.executor.memoryOverhead` 매개변수를 사용해 YARN 컨테이너에 자바 힙과는 별도의 추가 메모리 영역을 할당할 수 있다. 해당 메모리는 JVM 프로세스 자체를 실행하는 데 필요하다.

(3) 프로그램으로 실행자 리소스 설정

클러스터 배포 모드에서 실행자의 core, instance, memory 관련 매개변수를 사용하려면 `spark-defaults.conf` 파일이나 명령줄에 설정해야 한다.

## 7) 로그 조회

(1) 로그 취합 기능

`yarn-site.xml`의 `yarn.log-aggregation-enable` 매개변수를 true로 설정해 활성화한다. 집계된 로그 파일을 `yarn logs` 명령어로 조회할 수 있다.

`yarn logs --applicationId <application_id>` 

(2) 로깅 레벨 설정

커스텀 [log4j.properties](http://log4j.properties) 파일을 —files 인수로 전달하면 애플리케이션별로 LOG4J 설정을 적용할 수 있다.

## 8) 보안

kerberos화된 yarn cluster에 잡을 제출하려면 리눅스의 kinit 명령을 사용해 kerberos 인증을 수행해야 한다.

`kinit -kt <your_keytab_file> <your_service_principal>`

## 9) 동적 리소스 할당

동적 할당은 애플리케이션에 할당된 실행자 리소스를 임시로 회수해 다른 애플리케이션이 리소스를 사용할 수 있도록 하는 기능이다.

- `spark.dynamicAllocation.enabled` 를 true로 설정해 활성화한다.
- 외부 셔플링 서비스를 할당하지 않으면 동적 할당으로 종료된 실행자의 셔플링 파일을 요청할 때 이를 처음부터 다시 계산해야 하며 이는 리소스를 낭비하는 결과로 이어진다. 외부 셔플링 서비스를 사용하려면 `spark.shuffle.service.enabled` 를 true로 설정해야 한다.

`spark.dynamicAllocation.minExecutors` : 애플리케이션이 가질 수 있는 실행자의 최소 개수

`spark.dynamicAllocation.maxExecutors` : 애플리케이션이 가질 수 있는 실행자의 최대 개수

`spark.dynamicAllocation.initialExecutors` : 애플리케이션에 동적으로 할당할 실행자의 초기 개수

